networks:
  nginx-manager_customnetwork:
    external: true

services:
  zookeeper:
    restart: always
    image: confluentinc/cp-zookeeper
    container_name: ver-obspy-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - nginx-manager_customnetwork


  kafka:
    restart: always
    container_name: ver-obspy-kafka
    image: confluentinc/cp-kafka
    depends_on:
      - zookeeper
    ports:
      - '19092:19092'
      - '29092:29092'
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'ver-obspy-zookeeper:2181'
      KAFKA_LISTENERS: INSIDE://ver-obspy-kafka:9092,OUTSIDE://0.0.0.0:19092
      KAFKA_ADVERTISED_LISTENERS: INSIDE://ver-obspy-kafka:9092,OUTSIDE://85.209.163.202:19092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: '1'
    networks:
      - nginx-manager_customnetwork

  init-kafka:
    container_name: ver-obspy-init-kafka
    image: confluentinc/cp-kafka:6.1.1
    depends_on:
      - kafka
      - zookeeper
    entrypoint: ['/bin/sh', '-c']
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server 127.0.0.1:19092 --list
      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server 127.0.0.1:19092 --create --if-not-exists --topic seismic_preprocess --replication-factor 1 --partitions 4 --config segment.bytes=150000 --config retention.bytes=3000000 --config retention.ms=120000
      kafka-topics --bootstrap-server 127.0.0.1:19092 --create --if-not-exists --topic seismic_store --replication-factor 1 --partitions 4 --config segment.bytes=150000 --config retention.bytes=3000000 --config retention.ms=120000
      kafka-topics --bootstrap-server 127.0.0.1:19092 --create --if-not-exists --topic weather_preprocess --replication-factor 1 --partitions 4 --config segment.bytes=150000 --config retention.bytes=3000000 --config retention.ms=120000
      kafka-topics --bootstrap-server 127.0.0.1:19092 --create --if-not-exists --topic weather_store --replication-factor 1 --partitions 4 --config segment.bytes=150000 --config retention.bytes=3000000 --config retention.ms=120000
      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server 127.0.0.1:19092 --list
      "

  redis:
    image: redis
    container_name: ver-obspy-redis
    environment:
    - REDIS_PASSWORD=${REDIS_PASSWORD}
    command: redis-server --requirepass ${REDIS_PASSWORD}
    ports:
      - '6379:6379'
    volumes:
      - redis_data:/data

  seismic_source:
    image: confluentinc/cp-kafka
    depends_on:
      - redis
      - kafka
      - init-kafka
    build:
      context: ./seismic_source
      dockerfile: Dockerfile
    container_name: ver-obspy-seismic-source
    environment:
      - .seismic_source.env
    ports:
      - '8000:8000'
    restart: always

  mongo:
    image: mongo:latest
    container_name: ver-obspy-mongo
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_INITDB_ROOT_USERNAME}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_INITDB_ROOT_PASSWORD}
      MONGO_DB_NAME: ${MONGO_DB_NAME}
    volumes:
      - mongodb_data:/data
    networks:
      - nginx-manager_customnetwork
    ports:
      - "27018:27018"

volumes:
  redis_data:
  mongodb_data: